## Основные команды

***Настройка nginx:***
1. Основной каталог для сайтов /var/www/html
> [!important] Важно
> **Из других каталогов может не запуститься**

2. Изменение владельца запуска службы nginx:
```
sudo vim /etc/nginx/nginx.conf
	параметр: user
```

3. Для проверки можно попробовать получить статистику каталога от того пользователя под которым запущен сервер nginx и если будет **permission denied**, то таким образом следует, что nginx не может открыть файлы сайта.

4. Лучшим решением в этом случае будет добавить `www-data`в `username`группу:
```
gpasswd -a www-data username
```
   a) убедитесь, что `username`группа может войти во все каталоги по пути:
```
chmod g+x /home && chmod g+x /home/kvl && chmod g+x /home/kvl/html_css
```

***Проверка конфигурации:***

```
sudo nginx -t
```

***Безопасная перезагрузка службы***

```
sudo nginx -s reload
```


## Настройка основного конфигурационного файла

Узнаем количество процессоров в системе

`cat /proc/cpuinfo | grep processor | wc -l` или `nproc`

Заменить параметр worker_process на количество процессов

**worker_processes 1;**

**worker_rlimit_nofile 100000;**
Увеличивает лимит числа открытых файловых дескрипторов (FD). Если у NGINX будет много одновременных соединений, он сможет обслуживать их без ошибок вида "too many open files"

events {
	**worker_connections 4000;**
}
worker_connections задаёт, сколько одновременно входящих соединений (входящих запросов) может обрабатывать каждый worker. Увеличение этого значения даёт возможность обслуживать больше клиентов параллельно. Браузер одного клиента может открывать больше одного соединения. Чтобы понять какое число соединений может обработать процессор можно выполнить команду `ulimit -n` и стоит указать это число.

events {
	**use epoll;**
}
Epoll - высокопроизводительный механизм обработки событий в Linux. Улучшает масштабируемость и скорость реакции при большом числе одновременных соединений.

events {
	**multi_accept on;**
}
Разрешает worker-процессу принимать несколько новых соединений за один вызов. Ускоряет приём входящих соединений и снижает нагрузку на CPU при большом потоке запросов.

http {
**open_file_cache max=200000 inactive=20s;**
Включает кэширование дескрипторов открытых файлов и метаданных. Ускоряет доступ к часто запрашиваемым файлам, так как при повторном запросе не нужно повторно открывать файл с нуля

**open_file_cache_valid 30s; open_file_cache_min_uses 2; open_file_cache_errors on;**
Настройки для кэша открытых файлов: интервал проверки кэша (30s), минимальное число обращений к файлу, чтобы он оставался в кэше (2), и логирование ошибок при работе с кэшем (on). Все эти параметры помогают оптимизировать затраты га открытие файлов при нагруженных серверах.

**access_log off;**
Отключение журнала доступа снижает нагрузку на файловую систему и процессор, так как не нужно каждый запрос записывать в лог. Однако при отладке и боевой эксплуатации это может, поэтому в production-средах часто включают логи, но перенаправляют их на системы быстрой обработки или ротации.

**sendfile on;** 
Активация sendfile позволяет ядру копировать данные из файла в сокет напрямую, минуя пространство пользователя. Это уменьшает накладные расходы на системные вызовы (read + write) и повышает пропускную способность.

**tcp_nopush on;**
При включённом tcp_nopush (вместе с sendfile on) Nginx пытается отправлять заголовки и данные более крупными блоками, улучшая эффективность TCP-пакетизации и снижая overhead.

**tcp_nodelay on;**
Отключает ожидание накопления данных в буфере (Nagle\`s Algorithm). Полезно при отправке небольших ответов или данных в реальном времени, повышает отклик.

**gzip on;**
Включение gzip-сжатия уменьшает размер ответа, сокращает трафик и ускоряет передачу. Однако пр этом растёт нагрузка на CPU, так что уровень сжатия должен быть сбалансированным.

**gzip_min_length 10240; gzip_comp_level 1;**
 - gzip_min_length 10240 - Nginx не будет сжимать ответы меньше 10КБ, чтобы избежать неоправданных затрат CPU на мелкие ответы.
 - gzip_comp_level 1 - уровень сжатия (от 1 до 9). Уровень 1 - самый быстрый с минимальной нагрузкой на CPU.
 - gzip_vary on; gzip_disable msie6; gzip_proxied ...;

**gzip_vary on** добавляет заголовок Vary: Accept-Encoding, что помогает кэш-мерверам.
**gzip_disable msie6** отключает gzip для старых браузеров IE6 (известны проблемы).
**gzip_proxied expired no-cache no-store private auth;** указывает, в каких случаях gzip-трафик проксируется/сжимается. Все эти настройки повышают совместимость и экономят трафик.

**gzip_types** ...;
Определяет список типов контента, который стоит сжимать. Расширяет сжатие помимо text/html.

**reset_timedout_connection on;**
Если клиент завис и не отвечает, Nginx сбрасывает соединение. Это позволяет не держать "висящие" соединения, освобождая ресурсы.

**client_body_timeout 10;**
Уменьшает время ожидания получения тела запроса. Если клиент медленно отправляет данные или прерывается, это не будет долго держать соединение. Ускоряет освобождение ресурсов.

**send_timeout 2;**
Если клиент перестал читать ответ, Nginx через 2 секунды разорвет соединение. Это полезно при "зависших" клиентах и большой нагрузке.

**keepalive_timeout 30;**
keepalive_timeout 30 - соединение с клиентом сохраняется 30 секунд между запросами.

**keepalive_requests 100000** - заодно соединение клиент может сделать до 100000 запросов. использование keep-alive снижает расходы на установку нового TCP-соединения, но лимит и время нужно выбирать с учётом нагрузки.




## Настройка таймаутов

#### fastcgi_read_timeout

> Оптимальное значение для `fastcgi_read_timeout` зависит от времени выполнения ваших скриптов, но обычно рекомендуется устанавливать его в диапазоне ==от 60 секунд до 300 секунд (5 минут) или выше==, если вашему сайту требуется больше времени на обработку запросов. Важно, чтобы это значение было не меньше максимального времени выполнения ваших скриптов, например, параметра `max_execution_time` в PHP, чтобы избежать ошибок 504 Gateway Timeout


```
location ~ \.php$ {
    # ... другие директивы ...
    fastcgi_pass unix:/var/run/php/php7.4-fpm.sock; # пример, путь может отличаться
    fastcgi_param SCRIPT_FILENAME $document_root$fastcgi_script_name;
    include fastcgi_params;

    # Устанавливаем время ожидания для чтения данных из FastCGI
    # Здесь 300 секунд = 5 минут
    fastcgi_connect_timeout 180;
	fastcgi_send_timeout 180;
	fastcgi_read_timeout 180;

}
```

cat /etc/php8/fpm/php.ini

```
max_execution_time = 180
```



## Переменные:

1. Вывод переменной root:
	```
		return 200  $document_root;
	```

## Директивы:
### Директива server_name \_;

> [!NOTE] Описание
> `server_name _` - используется для обозначения любого имени хоста, которое не совпадает ни с одним из явно указанных имён серверов

#### Пример:

![[Screenshot 2025-06-03 144859.png]]
В этом примере, первый блок сервера обрабатывает запросы к домену `example.com`. 
Второй блок сервера с `server_name _` будет обрабатывать любые другие запросы, не соответствующие первому

### Директивы redirect и rewrite

* **Редиректы на Nginx: Rewrite vs Return** 

Довольно часто при обращении к сайту используются **редиректы на уровне вебсервера Nginx**. Чаще всего редиректы применяют для изменения имени домена (без www на домен с www) или протокола (с HTTP на HTTPS).

Настройку на редиректов в NGINX можно сделать двумя способами — давайте разберемся!

Пример настройки редиректа с домена без www на домен с www:

```text
server {
        server_name example.com;
        # Вариант 1
        return 301 $scheme://www.$host$request_uri;
 
        # Вариант 2
        rewrite ^ http://www.$host$request_uri? permanent;
}
```

Пример редиректа с HTTP на HTTPS:

```text
server {
        server_name example.com;
        # Вариант 1
        return 301 https://$server_name$request_uri;
 
        # Вариант 2
        rewrite ^ https://$server_name$request_uri? permanent;
}
```

Рассмотрим подробнее вариант с использованием директивы `rewrite`:

```text
rewrite ^ http://$host$request_uri? <флаг>; 
```

Здесь:

- `$host` — имя хоста из запроса, если отсутствует — имя в поле «Host» заголовка, если тоже отсутствует — имя сервера;
- `$request_uri` — первоначальный запрос с аргументами (все, что идет после доменного имени).

Флаги могут принимать следующие значения:

- `permanent` — редирект с кодом 301.
- `redirect` — редирект с кодом 302.
- `last` — закончить обработку с переходом в новый `location`.
- `break` — закончить обработку и остаться в текущем `location`.

В вариант с использованием директивы `return`:

```text
return <код> https://$host$request_uri;
```

коды могут использоваться любые, но чаще всего — 301, 302, 404.

Для обычного посетителя сайта разницы между кодами 301 и 302 нет. А вот для поискового робота разница огромная — 301-й редирект говорит о «склеивании» страниц. Это означает для поисковика то, что старая и новая страницы — это одно и тоже. Таким образом результаты ранжирования необходимо сохранить для новой страницы. 302-й редирект просто говорит о том, что нужно перейти по другому адресу. Поисковый робот не сохраняет результат выдачи для новой страницы, индексируя его с нуля.

Ключевые особенности обоих вариантов:

**REWRITE**

- переписывается только та часть исходного URL, которая соответствует регулярному выражению;
- медленнее, чем `return`;
- возвращает HTTP 302 (Moved Temporarily) во всех случаях, кроме явно указанного флага permanent;
- лучше подходит для временного изменения URL.

**RETURN**

- весь URL-адрес переписывается на указанный URL-адрес;
- быстрее, чем `rewrite`;
- возвращает HTTP 301 (Moved Permanently);
- лучше подходит для постоянного изменения URL-адреса;
- не нужно устанавливать флаг `permanent`

### Директива types_hash_max_size

> [!NOTE] Описание
> `types_hash_max_size` - определяет максимальный размер хеш-таблицы, используемой для хранения соответствий между типами файлов и их MIME-типами.
> - Значение по умолчанию обычно является 2048, что может быть достаточным для большинства веб-сайтов.
> - Для больших сайтов с большим разнообразием типов файлов может потребоваться увеличение этого значения.
> - Не стоит увеличивать значение без необходимости, так как это может привести к увеличению потребления памяти.
>
> `types_hash_max_size` - важная директива, влияющая на производительность Nginx при обслуживании статических файлов.

#### Пример:
![[Screenshot 2025-06-10 114118.png]]

### Директива gzip_vary on

> [!NOTE] Описание
> Директива `gzip_vary on` в Nginx включает добавление в HTTP-заголовки ответа заголовка `Vary: Accept-Encoding`. 
> Этот заголовок сообщает браузерам, что сервер отправляет разные версии ответа (сжатые и несжатые), 
> в зависимости от того, поддерживает ли браузер сжатие Gzip

Объяснение:

- **Gzip:**
    
    Gzip - это популярный алгоритм сжатия данных, который используется для уменьшения размера файлов, передаваемых через интернет. 
    

- `Vary: Accept-Encoding`:
    
    Этот заголовок в HTTP-ответе указывает, что сервер может отправлять разные версии ресурса в зависимости от значения заголовка `Accept-Encoding` в запросе клиента. 
    

- `Accept-Encoding`:
    
    Заголовок `Accept-Encoding` в HTTP-запросе указывает, какие методы сжатия данных поддерживает браузер (например, `gzip`, `deflate`). 
    

- `gzip_vary on`:
    
    Когда `gzip_vary on` включен в конфигурации Nginx, сервер добавляет заголовок `Vary: Accept-Encoding` к ответам, которые были сжаты с использованием Gzip. 
    

- **Для чего это нужно:**
    
    Это важно для корректной работы кэширования. Если браузер поддерживает Gzip, он получит сжатую версию страницы, если нет - получит несжатую. Заголовок `Vary: Accept-Encoding` гарантирует, что браузер будет кэшировать только те версии страницы, которые он сможет правильно обработать.
#### Пример:
![[Снимок экрана от 2025-06-17 15-18-05.png]]

### Директива gzip_proxied any

> [!NOTE] Описание
> gzip_proxied any; — сжимать данные ответов для proxy-серверов

### Директива gzip_min_length

 > [!NOTE] Описание
> gzip_min_length 100; — Минимальный размер файла для сжатия 100 байт (по умолчанию 20)
  

## Выпуск сертификата LetsEnCrypt c помощью certbot

`sudo apt install certbot python3-certbot-nginx



> [!NOTE] Замечание
> Перед выпуском сертификата не должно быть директивы ssl_certificate с указанием путей к ключам, а именно блока server
> и открыт порт 80 на firewall


![[Снимок экрана от 2025-06-05 11-46-14.png]]

Добавляем сертификаты в конфигурационный файл сайта:

![[Снимок экрана от 2025-06-05 12-02-10.png]]

Создать снипет конфигурационный файл отвечающий за общие настройки ssl

`sudo vim /etc/nginx/snippets/ssl-params.conf
![[ssl_params.conf]]

Настройка задачи по обновлению сертификата:

`sudo crontab -e

+++ @daily certbot renew
## Настройка из под пользователя:
***Работа с разрешениями на папки для пользователей (например для nginx):***

Создадим непривилегированного пользователя, в нашем случае webuser:
```
adduser webuser
```
Появится интерактивный диалог, в ходе которого необходимо будет задать пароль (New password), подтвердить его (Retype new password), остальные пункты можно не заполнять, просто нажимая ENTER. В последнем вопросе Is the information correct? [Y/n] необходимо нажать Y и нажать ENTER.

Добавляем пользователя webuser в группу sudo для повышения привилегий:
```
usermod -aG sudo webuser
```


Задаем владельца каталогов и находящихся внутри файлов:
```
chown -R webuser:webuser /home/webuser/www/
```

```
chown -R webuser:webuser /home/webuser/tmp/
```

Добавляем пользователя www-data в группу webuser:
```
usermod -aG webuser www-data
```

## Настройки для сайтов

##### 1. Переход в другой location

##### 1.1 Перенаправление в другой блок выполняется за счет одной из приведенных ниже директив:

1. **try_files**
2. **rewrite**
3. **error_page**

	***Пример 1:***
		
		location / {
			try_files $uri $uri.html $uri/ /none/index.html;
		}
		location /none {
			root /var/sites/new
		}
	При поступлении запроса к example.com/request Nginx первым делом увидит **$uri** и попытается найти location request. Такого нет, далее следует поиск _request.**html**_ и каталога _request_. Если таких нет, то запрос переадресуется в резервный _location_ на страницу _/none/index.html_. Веб-сервер выдаст пользователю содержимое _/var/sites/new/none/index.html_

	***Пример 2:***
		
		server_name www.firesdash.test.local firesdash.test.local
		location / {
			root /var/www/html/fron/firesdash.ru/dist;
			index index.html;
			try_files $uri /index.html;
		}
	При поступлении запроса к example.com/request Nginx первым делом увидит **$uri** и попытается найти location request. Такого нет и веб сервер откроет /var/www/html/fron/firesdash.ru/dist/**index.html**. А при поступлении запроса firesdash.test.local (www.firesdash.test.local) Nginx открывает **index** либо **index.html**

	***Пример 3:***
		
		server_name www.firesdash.test.local firesdash.test.local
		location / {
			root /var/www/html/fron/firesdash.ru/dist;
			index index.html;
			try_files $uri $uri/ =404;
		}
	При поступлении запроса к example.com/request Nginx первым делом увидит **$uri** и попытается найти location request. Такого нет и веб сервер откроет вернёт ошибку 404

	***Пример 4:***

		server {
		    listen 80;
		    server_name example.com;
		
		    root /var/www/example.com;
		
		    location /old-folder/ {
		        rewrite ^/old-folder/(.*)$ /new-folder/$1 permanent;
		    }
		
		    location / {
		        try_files $uri $uri/ =404;
		    }
		}
- `listen 80;` указывает, что сервер слушает порт 80.
- `server_name example.com;` указывает имя сервера.
- `root /var/www/example.com;` определяет корневую директорию для сайта.
- `location /old-folder/ { ... }` определяет блок для обработки запросов к `/old-folder/`.
- `rewrite ^/old-folder/(.*)$ /new-folder/$1 permanent;` перезаписывает URL.
    - `^/old-folder/(.*)$` - регулярное выражение, которое соответствует всем запросам, начинающимся с `/old-folder/`. `$1` содержит захваченную часть URL после `/old-folder/`.
    - `/new-folder/$1` - новый путь, куда перенаправляется запрос. В данном случае, все запросы к `/old-folder/something` будут перенаправлены на `/new-folder/something`.
    - `permanent` - указывает на постоянное перенаправление (код 301). Это означает, что браузер запомнит новое местоположение ресурса. Используйте `redirect` (код 302) для временного перенаправления.
- `location / { ... }` - блок для обработки всех остальных запросов.
- `try_files $uri $uri/ =404;` - проверяет наличие файла или директории, соответствующей запрошенному URI, и возвращает 404 ошибку, если ничего не найдено.

Важно:
- Убедитесь, что директория `/var/www/example.com/new-folder` существует и доступна для Nginx.
- После внесения изменений в конфигурацию, не забудьте перезагрузить Nginx: `sudo nginx -s reload`.
- Если вы используете директиву `permanent`, убедитесь, что перенаправление действительно нужно, так как это постоянное изменение, которое браузер кэширует. Для временных перенаправлений используйте `redirect` (код 302).
- Регулярные выражения в `rewrite` могут быть сложными. Начните с простых примеров и постепенно усложняйте их, если это необходимо.
- Существуют разные варианты использования `rewrite`, в зависимости от конкретной задачи. Например, можно перенаправлять запросы на разные серверы или изменять URL для обработки на бэкенде. Более подробную информацию можно найти в документации Nginx.
##### 2. Отключение кэширования

```ruby
add_header Cache-Control 'no-store, no-cache, must-revalidate, proxy-revalidate, max-age=0';
```

**no-store** - не кэшировать ответ.
**no-cache** - Это фактически позволяет кэшировать ответ, хотя он немедленно помечается как устаревший и всегда повторно проверяется исходным сервером.
**must-revalidate** - означает только, что устаревший кэшированный документ должен быть повторно проверен исходным сервером.
**proxy-revalidate** - аналогично must-revalidate, за исключением того, что применяется только к кэшам прокси.

##### 3. Кэширование статических файлов

```
# assets, media
location ~* \.(?:css(\.map)?|js(\.map)?|jpe?g|png|gif|ico|cur|heic|webp|tiff?|mp3|m4a|aac|ogg|midi?|wav|mp4|mov|webm|mpe?g|avi|ogv|flv|wmv|geojson)$ {
	expires	7d;
	access_log on;
}

#svg, fonts
location ~* \.(?:svgz?|ttf|ttc|otf|eot|woff2?)$ {
	add_header Access-Control-Allow-Origin "*";
	expires	7d;
	access_log on;
}

```
> Обратите внимание на то, что nginx не отдает заголовки Expires. Если для сгенерированных интерпретатором PHP документов это не всегда важно, то статические данные желательно отдавать с подобным заголовком, позволяя броузерам посетителей более активно использовать кэширование. В данном конфигурационном блоке есть раздел location для обработки статических докуменов. Именно в этом блоке добавьте строку expires Xd, где Х — количество дней валидности данных. Например, expires 7d укажет броузеру, что изображения и файлы CSS/JS можно кэшировать на протяжении недели.

***пример с моего сервера:***
```
location ~* \.(jpg|jpeg|gif|ico)$ {
                access_log off;
                # Кеширум на 1 минуту (s - секунда, h - час, d - день, M - месяц)
                expires 1m;
                # Более старый способ записи add_header Cache-Control public;
                add_header Pragma public;
                # Кешируем везде (и на прокси и на клиентах). 
                # private - кэширование только на браузере пользователя
                # no-cache - нельзя кэшировать
                add_header Cache-Control public;
                # Для разных клиентов (браузеров), заправшивающих один и тот же ресурс, сервер может отдавать разные версии ответа, сжатые разными способами.
                add_header Vary Accept-Encoding;
        }
```

##### 4. Блокировка скрытых файлов
```
location ~ /\. {
                deny all;
                return 403;
        }
```
> Запретить доступ к скрытым файлам

![[Снимок экрана от 2025-07-24 18-19-40.png]]
##### 5. Настройка php-fpm

Установка php-fpm [Статья](https://losst.pro/ustanovka-nginx-i-php-fpm-v-ubuntu-20-04)

![[Снимок экрана от 2025-04-11 11-54-24.png]]
> Все файлы в запросе (http://localhost/api.php) оканчивающиеся на .php будут запускаться (выполняться), а не загружаться.

##### 6. Пропуск favicon.ico

```python
# skip favicon.ico
#
location = /favicon.ico {
    access_log off;
    return 204;
}
```


## Настройка nginx в качестве балансировщика

[Ссылка на статью habr.com](https://habr.com/ru/companies/first/articles/683870/)

- ***Создаём новый файл конфигурации для балансировщика нагрузки***
```
cd /etc/nginx/sites-available/ ; sudo vim proxy_to_srv
```

Содержимое файла:
```
upstream proxy_to_srv {
    server 192.168.192.101:80;
}

upstream proxy_to_landing {
    server 192.168.192.101:8080;
}

upstream proxy_to_default {
    server 192.168.192.101:8000;
}

# Этот сервер принимает весь трафик на порт 80 и передает его вышестоящему потоку.
# Обратите внимание, что имя вышестоящего потока и proxy_pass должны совпадать.

server {
    listen 80;
  
    server_name www.firesdash.test.local firesdash.test.local;
  
    location / {
        include proxy_params;
      
        proxy_pass http://proxy_to_srv;
      
        proxy_redirect off;
        proxy_http_version 1.1;
        proxy_set_header Upgrade $http_upgrade;
        proxy_set_header Connection "upgrade";
    }
}

server {
    listen 80;
  
    server_name www.landing.test.local landing.test.local;
  
    location / {
        include proxy_params;
      
        proxy_pass http://proxy_to_landing;
      
        proxy_redirect off;
        proxy_http_version 1.1;
        proxy_set_header Upgrade $http_upgrade;
        proxy_set_header Connection "upgrade";
    }
}

server {
    listen 80 default_server;
    #   server_name default_server; 
    #   server_name www.landing.test.local landing.test.local;
  
    location / {
        include proxy_params;
      
        proxy_pass http://proxy_to_default;
      
        proxy_redirect off;
        proxy_http_version 1.1;
        proxy_set_header Upgrade $http_upgrade;
        proxy_set_header Connection "upgrade";
    }
}

```

> [!NOTE] Описание
> _**Upstream** определяет, куда Nginx будет передавать запросы после их получения_
> _**listen** определяет порт 80, через который Nginx будет получать запросы_
> _**proxy_pass** используется для указания NGINX, _куда отправлять получаемый трафик_
> _**server_name \_** используется для обозначения любого имени хоста, которое не совпадает ни с одним из явно указанных имён серверов_
> <h5>Общее описание</h5>
> nginx принимает запросы на 80 порту для трёх сайтов, но в зависимости от server_name<br>
> (адреса введенного в url) он отправаляет на один из трех блоков.<br>
> <hr>
> 
> **Например**: если ввести в адресную строку http://firesdash.test,local он отправит в первую
> секцию, т.к. server_name = firesdash.test.local, но если ввести в адресную строку
> http://firesdash он отправит уже в секцию по умолчанию, которая определяется в третьем
> блоке, а именно listen 80 **default_server;**
> 






## Кракозябры при отображении страницы:

Решение:

![[Снимок экрана от 2025-06-02 15-45-19.png]]

## Перенаправление location на ошибку 404 или 403:

**Ошибка 404** - *страница не найдена*

![[Снимок экрана от 2025-07-17 11-48-30.png]]

> [!NOTE] Объяснение
> В этом примере, при запросе на `/quiz_v4.kvlpro.ru/wp-admin`, Nginx сначала попробует обработать запрос как обычно. 
> Если ресурс не будет найден, то будет возвращен код 404. Затем, директива `error_page 404 /404.html;` 
> перенаправит запрос на `/404.html`. Директива `return 404;` устанавливает код ответа 404 для этого конкретного location. 
> В `location /404.html` определен путь к файлу 404.html, а директива `internal` делает этот `location` доступным только 
> для внутренних перенаправлений, т.е. его нельзя будет запросить напрямую.

**Ошибка 403** - *доступ запрещен*

![[Снимок экрана от 2025-07-17 14-49-45.png]]

> [!NOTE] Объяснение
> В этом примере, при запросе на `/quiz_v4.kvlpro.ru/wp-admin`, Nginx сначала попробует обработать запрос как обычно. 
> Если ресурс не будет найден, то будет возвращен код 404. Затем, директива `error_page 403 /403.html;` при коде ответа 403
> перенаправит запрос на `/403.html` с кодом ответа 403. В `location /403.html` определен путь к файлу 403.html, а директива `internal` 
> делает этот `location` доступным только для внутренних перенаправлений, т.е. его нельзя будет запросить напрямую.

## Сетевое тестирование
**Программа:**
https://github.com/wg/wrk

**Установка:**
git clone https://github.com/wg/wrk.git
cd wrk
make
sudo cp wrk /usr/local/bin
cd..
sudo rm -r wrk/
		или использовать пакетный менеджер snap
sudo snap install wrk2

**Запуск:**
wrk -t12 -c400 -d30s --latency http://127.0.0.1:80
*запустить 12 потоков, установить 400 сединений и в течении 30 секунд кидать get запросы на localhost*

wrk2 -t12 -c400 -d30s --latency -R1000 https://kvlpro.ru
использовать 12 (кол-во цпу) потоков и 400 соединений (количество одновременных запросов) в течении 30 секунд с частотой 1000 запросов в секунду

### Тестирование моего сервера

> [!NOTE] Замечание по параметрам команды wrk
> Параметр `-c` означает количество соединений. В одном соединении может быть разное количество запросов (`request`). 
> Предполагаю зависит от качество соединения и т.д. 
> Для примерного определения среднего количества запросов за единицу времени можно выполнить `wrk -t1 -c1 -d1s https://www.testing.kvlpro.ru`
> Таким образом при записи `wrk -t1 -c1 -d1s https://www.testing.kvlpro.ru` будет одно соединение и 20 запросов.
> А при записи `wrk -t1 -c2 -d1s https://www.testing.kvlpro.ru` будет два соединения и примерно чуть меньше 40 запросов (по 20 запросов на соединение).
> А при записи `wrk -t1 -c1 -d2s https://www.testing.kvlpro.ru` будет как и до этого около 40 запросов (20 запросов \* 2сек).

![[Снимок экрана от 2025-06-20 15-32-27.png]]

***nginx.conf: -> rate=1r/s (пропускает 1 запрос в секунду вне зависимости от количества соединений)
location /: -> burst=1***

> [!success] Title
> `wrk -t1 -c1 -d1s https://www.testing.kvlpro.ru`
> ==Результат:== 1 запрос (request), при этом ошибки не будут фиксироваться, т.к. параметр burst равен количеству соединений (-с1 и burst=1)
> ![[Снимок экрана от 2025-06-20 15-41-04.png]]
> ![[Снимок экрана от 2025-06-20 15-41-31.png]]

***nginx.conf: -> rate=17r/s (разрешено 17 запрос в секунду вне зависимости от количества соединений)
location /: -> burst=1***

> [!success] Title
> `wrk -t1 -c1 -d1s https://www.testing.kvlpro.ru`
> ==Результат:==  около 17 запросов (request), при этом ошибки не будут фиксироваться, т.к. параметр burst равен количеству соединений (-с1 и burst=1)
> ![[Снимок экрана от 2025-06-20 15-46-03.png]]
> ![[Снимок экрана от 2025-06-20 15-46-29.png]]

***nginx.conf: -> rate=2r/s (пропускает 2 запроса в секунду вне зависимости от количества соединений)
location /: -> burst=2 (разрешено 2 соединения)*** 

> [!success] Title
> `wrk -t1 -c2 -d1s https://www.testing.kvlpro.ru`
> ==Результат:==  2 запроса (request), при этом ошибки не будут фиксироваться, т.к. параметр burst равен количеству соединений (-с2 и burst=2)
> ![[Снимок экрана от 2025-06-20 16-33-33.png]]
> ![[Снимок экрана от 2025-06-20 16-34-17.png]]
> ***==где код 499 количество соединений отработавших в холостую
> У нас разрешено 2 запроса в секунду, а по факту одно соединение может обработать 20 запросов, а т.к.
> у нас выполняется два соединения (-c2), но ни одно из них на всю катушку не отработало, то соответственно
> 499 кода возврата у нас 2 штуки.==***

***nginx.conf: -> rate=40r/s** (пропускает 40 запроса в секунду при этом одно соединение может обработать около 20 запросов,
но т.к. у нас два соединения то результатом будет примерно 40 запросов)
***location /: -> burst=2 (разрешено 2 соединения)*** 

> [!success] Title
> `wrk -t1 -c2 -d1s https://www.testing.kvlpro.ru`
> ==Результат:==  36 запросов (общее количество request - (удачных+отклоненных)), при этом ошибки не будут фиксироваться, т.к. параметр burst равен количеству соединений (-с2 и burst=2)
> ![[Снимок экрана от 2025-06-20 16-42-32.png]]
> ![[Снимок экрана от 2025-06-20 16-43-42.png]]

***nginx.conf: -> rate=20r/s** (пропускает 20 запроса при этом одно соединение может обработать около 20 запросов,)
***location /: -> burst=1 (разрешено 2 соединения)*** 

> [!warning] Title
> `wrk -t1 -c2 -d1s https://www.testing.kvlpro.ru`
> ==Результат:==  35 запросов (общее количество request - (удачных+отклоненных)), при этом зафиксируются ошибки 503, т.к. разрешенное количество соединений одно (параметр burst=1),
> а запущено на серевер два соединения (-с2). Т.е. по факту мы должны получить около 20 успешных запросов, что и видно если из общего количества 35 вычесть неудачные (Non-2xx or 3xx responses: 17)
> получается 18 успешных запросов, что соответствует параметру rate=20r/s, а остальные 17 запросов отклонены
> ![[Снимок экрана от 2025-06-20 17-07-30.png]]
> ![[Снимок экрана от 2025-06-20 17-08-14.png]]


**Примеры тестирования:**
***Пример 1 (worker_processes 1; worker_connections 768;)***
wrk -t4 -c2000 -d30s --latency https://kvlpro.ru
![[Снимок экрана от 2025-06-09 16-55-07.png]]
Средняя Latency: 99.63ms (неплохой результат 19.09ms)
Среднее количество запросов в секунду: 1.42k
Latency Distribution (распределение по времени задержки):
	50% было быстрее 90.68ms
	99% можно брать как худший показатель
Было выполнено 162180 запросов за 30 секунд
Socket errors (ошибки):
	1503 ошибки коннекта
	18974 ошибок чтения
	timeout 2 ошибки таймаута
5389 запросов в секунду

***Пример 2 (worker_processes 1; worker_connections 768;)***
wrk -t4 -c768 -d30s --latency https://kvlpro.ru
![[Снимок экрана от 2025-06-09 17-07-00.png]]
## Инфа с курсов:

==***Получение заголовков ответа с сервера:***==

![[Снимок экрана от 2025-06-10 12-03-14.png]]
**Статус ответа:** 200
**Content-type:** text/css

***Если у нас идет перенаправление запроса (например c без www на www) то мы увидим следующее:***
![[Снимок экрана от 2025-06-10 12-06-49.png]]
**Статус ответа:** 301 (статус ответа перенаправление)
**Content-type определяется не корректно:** text/html

Поэтому при вызове команды curl надо вызывать напрямую сайт www

==***Возврат текста через return вместо скачивания файла:***==

По умолчанию при вызове return с кодом 200 и информационным сообщением, вместо вывода на экран сообщение происходит скачивание файла, внутри которого находится информационное сообщение. Такое поведение обусловлено тем, что в файле nginx.conf в директиве http по умолчанию назначен default_type application/octet-stream; 
![[Снимок экрана от 2025-06-10 13-09-37.png]]
![[Снимок экрана от 2025-06-10 13-09-47.png]]
Чтобы переназначить поведение по умолчанию можно переопределить default_type либо глобально в директиве http файла nginx.conf либо в настройках виртуального хоста в секции server сайта
![[Снимок экрана от 2025-06-10 13-21-34.png]]
![[Снимок экрана от 2025-06-10 13-21-45.png]]

***==Поведение location:==***

![[Снимок экрана от 2025-06-10 13-29-45.png]]
![[Screenshot 2025-06-10 133005.png]]
![[Screenshot 2025-06-10 133023.png]]

***==Можно отключать логи для статических файлов, таких как картинки:==***

Т.к. файлов может быть огромное количество, то будет напрягаться процессор и диск, и увеличиваться размер файла лога:
![[Снимок экрана от 2025-06-10 17-23-50.png]]

а также изменять уровень логирования:
**error_log** - [stderr|debug|info|notice|warn|error|crit|alert|emerg]
**access_log** - имеет другие параметры
[error_log](https://nginx.org/en/docs/ngx_core_module.html?&_ga=2.205744346.856361071.1749565721-1137248912.1749565721#error_log)
[access_log](https://nginx.org/en/docs/http/ngx_http_log_module.html?&_ga=2.268790840.856361071.1749565721-1137248912.1749565721#access_log)



## Проверка сертификатов:

**For RSA Keys**

Для проверки связи между закрытым ключом, CSR, цепочкой сертификатов и листом сертификата с помощью md5. 
Извлеките модуль из ключей и передайте его в openssl md5. Если md5 совпадает, то связь успешно проверена.

```bash
# Private Key
openssl rsa -noout -modulus -in rsa-domain-private.key | openssl md5

# CSR 
openssl req -noout -modulus -in rsa-certificate-signing-request-for-certificate-authority.csr | openssl md5

# Certificate from CA (Certificate Chain or Leaf Certificate, both will give same result)
openssl x509 -noout -modulus -in certificate-chain.crt | openssl md5
```

**For ECDSA Keys**

Для проверки связи между закрытым ключом, CSR, цепочкой сертификатов и листом сертификата с помощью md5. 
Извлеките открытый ключ из любого из ключей и передайте его в openssl md5. Если md5 совпадает, связь успешно проверена.

```bash
# Private Key
openssl ec -in ecdsa-domain-private.key -pubout | openssl md5

# CSR 
openssl req -in ecdsa-certificate-signing-request-for-certificate-authority.csr -noout -pubkey | openssl md5

# Certificate from CA (Certificate Chain or Leaf Certificate, both will give same result)
openssl x509 -in certificate-chain.crt -pubkey -noout | openssl md5
```

Пример вывода будет выглядеть так:

```bash
MD5(stdin)= 93739e80546792e8be2a61803467b7665c
MD5(stdin)= 93739e80546792e8be2a61803467b7665c
MD5(stdin)= 93739e80546792e8be2a61803467b7665c
```
## Примеры 

- #### Одновременный запуск http и https

```perl
Файл /etc/nginx/sites-available/default

server {
	listen 80 ;
	listen [::] ;
	root /var/www/html;
	index index.html index.htm index.nginx-debian.html;
	server_name firesdash.ru www.firesdash.ru;
	location{
		try_files $uri &uri/ =404;
	}
}
server {
 	listen 443 ssl;
 	listen [::]443 ssl;
 	server_name firesdash.ru www.firesdash.ru;
 	root /var/www/html;
 	index index.html index.htm index.nginx-debian.html;
 	ssl_certificate /etc/ssl/firesdash.ru.cert
 	ssl_certificate_key /etc/ssl/firesdash.ru.key
 	location{
 		try_files $uri &uri/ =404;
 	}
 }
```

